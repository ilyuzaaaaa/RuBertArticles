{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RuBertArticles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilyuzaaaaa/RuBertArticles/blob/main/RuBertArticles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGz8z13vF84k",
        "outputId": "5e87156e-242b-4429-883e-34443699172e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIC6AQ5hKgtV"
      },
      "source": [
        "!cp \"gdrive/My Drive/Transformer/modeling.py\" .\n",
        "!cp \"gdrive/My Drive/Transformer/optimization.py\" .\n",
        "!cp \"gdrive/My Drive/Transformer/tokenization.py\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2_VPDaUJLTy"
      },
      "source": [
        "import tokenization \n",
        "import torch\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from modeling import BertConfig, BertForSequenceClassification\n",
        "from optimization import BERTAdam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob5ceiKvIxj4",
        "outputId": "3688a0d9-80eb-441c-a875-d7129cf74638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df = pd.read_csv('./gdrive/My Drive/dataset_5.csv', encoding='utf8')\n",
        "df = df[['topics', 'title']]\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33068, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topics</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sport</td>\n",
              "      <td>Суд американского города Торранс приступит к р...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sport</td>\n",
              "      <td>Состояние здоровья знаменитого канадского хокк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>Финский \"Йокерит\" потеряет преимущество своей ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>\"Сакраменто\" проиграл \"Мемфису\" в матче чемпио...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sport</td>\n",
              "      <td>ФК \"Валенсия\": сделаем все, чтобы найти фаната...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  topics                                              title\n",
              "0  sport  Суд американского города Торранс приступит к р...\n",
              "1  sport  Состояние здоровья знаменитого канадского хокк...\n",
              "2  sport  Финский \"Йокерит\" потеряет преимущество своей ...\n",
              "3  sport  \"Сакраменто\" проиграл \"Мемфису\" в матче чемпио...\n",
              "4  sport  ФК \"Валенсия\": сделаем все, чтобы найти фаната..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGHclaZXJErP",
        "outputId": "008b561a-7be9-4606-8f19-71e67d55b05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "maps = pd.factorize(df.topics)[1]\n",
        "print(maps)\n",
        "df['topics'] = pd.factorize(df.topics)[0]\n",
        "print(df.head())\n",
        "df['title'] = df['title'].astype('str')\n",
        "for c in df:\n",
        "    if df[c].dtype == 'object':\n",
        "        print('Max длина предложения %s: %s\\n' %  (c, df[c].map(len).max()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sport', 'society', 'auto', 'business', 'economic'], dtype='object')\n",
            "   topics                                              title\n",
            "0       0  Суд американского города Торранс приступит к р...\n",
            "1       0  Состояние здоровья знаменитого канадского хокк...\n",
            "2       0  Финский \"Йокерит\" потеряет преимущество своей ...\n",
            "3       0  \"Сакраменто\" проиграл \"Мемфису\" в матче чемпио...\n",
            "4       0  ФК \"Валенсия\": сделаем все, чтобы найти фаната...\n",
            "Max длина предложения title: 162\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAlqGGkUj43W"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0854Ic2K2zm"
      },
      "source": [
        "sentences = df['title'].values\n",
        "labels = df['topics'].to_list()\n",
        "assert len(sentences) == len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGrem6pgJlUO"
      },
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, label):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.label = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euvah3iaJwgO"
      },
      "source": [
        "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, shuffle=True,test_size=0.3, random_state=42)\n",
        "assert len(set(train_gt)) == len(set(test_gt))\n",
        "num_classes = len(set(train_gt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rasNRaK-5V"
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(vocab_file='./gdrive/My Drive/Transformer/vocab.txt', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5vBhys1LIRA"
      },
      "source": [
        "def preprocessing(sentences, labels, tokenizer, max_len):\n",
        "    features = []\n",
        "    for i,sentence in enumerate(sentences):\n",
        "        \n",
        "        tokens_a = tokenizer.tokenize(sentence)\n",
        "        \n",
        "        if len(tokens_a) > max_len - 2:\n",
        "            tokens_a = tokens_a[0:(max_len - 2)]\n",
        "\n",
        "        tokens = []\n",
        "        tokens.append(\"[CLS]\")\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "        tokens.append(\"[SEP]\")\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        while len(input_ids) < max_len:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            \n",
        "        assert len(input_ids) == max_len\n",
        "        assert len(input_mask) == max_len\n",
        "\n",
        "        features.append(\n",
        "                    InputFeatures(\n",
        "                            input_ids=input_ids,\n",
        "                            input_mask=input_mask,\n",
        "                            label=[labels[i]]))\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEphZufULkz5"
      },
      "source": [
        "class Dataload(torch.utils.data.Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        \n",
        "        return torch.LongTensor(self.features[index].input_ids),\\\n",
        "               torch.LongTensor(self.features[index].input_mask),\\\n",
        "               torch.LongTensor(self.features[index].label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IQl340XLnAl"
      },
      "source": [
        "features = preprocessing(train_sentences, train_gt, tokenizer, 512)\n",
        "dataset_train = Dataload(features)\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset_train,batch_size = 8, shuffle=True,\\\n",
        "                                               num_workers=6, pin_memory=True)\n",
        "features = preprocessing(test_sentences, test_gt, tokenizer, 512)\n",
        "dataset_test = Dataload(features)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset_test,batch_size = 1, shuffle=False,\\\n",
        "                                               num_workers=6, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_HXnNyJNTzK",
        "outputId": "93486377-1daf-411f-f204-6768f68905a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2894\n",
            "9921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAG-OHNRLonQ",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "device = 'cuda'\n",
        "bert_config = BertConfig.from_json_file('./gdrive/My Drive/Transformer/bert_config.json')\n",
        "model = BertForSequenceClassification(bert_config, num_classes)\n",
        "model.bert.load_state_dict(torch.load('./gdrive/My Drive/Transformer/pytorch_model.bin'\\\n",
        "                                      , map_location='cpu'))\n",
        "model.to(device)\n",
        "model = torch.nn.DataParallel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiEZ389LMht3",
        "outputId": "3b8088c6-5d5f-4965-c7c2-d12993b2a007",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 21 10:00:00 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    69W / 149W |   1100MiB / 11441MiB |     28%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_f3pgMFMqlU",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "num_epoch = 5\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_parameters = [\n",
        "     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "     ]\n",
        "num_train_steps = len(train_dataloader) * num_epoch\n",
        "optimizer = BERTAdam(optimizer_parameters,\n",
        "                     lr=5e-5,\n",
        "                     warmup=0.1,\n",
        "                     t_total=num_train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZhiWqlxlrR9",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "f = open('log.txt', 'w')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw2bxxr0MtSd"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "train_loss_set = []\n",
        "\n",
        "batch_iterator = iter(train_dataloader)\n",
        "\n",
        "total_step = 0\n",
        "model.train()\n",
        "train_loss = 0\n",
        "\n",
        "while total_step<5*len(train_dataloader):\n",
        "\n",
        "    total_step += 1\n",
        "    try:\n",
        "        batch = next(batch_iterator)\n",
        "    except:\n",
        "        batch_iterator = iter(data_loader)\n",
        "        batch = next(batch_iterator)\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss, logits = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels.squeeze(1), token_type_ids=None)\n",
        "    \n",
        "    train_loss_set.append(loss.mean().item())\n",
        "\n",
        "    loss.mean().backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.mean().item()\n",
        "\n",
        "    clear_output(True)\n",
        "    plt.plot(train_loss_set)\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    if total_step%1000 == 0:\n",
        "        print(\"Mean loss: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "        with open('log.txt', 'a') as f:\n",
        "            f.write(\"Mean loss: {0:.5f}\\n\".format(train_loss / len(train_dataloader)))\n",
        "        torch.save(model.state_dict(), './gdrive/My Drive/weights'+str(total_step)+'.pth')\n",
        "        train_loss = 0\n",
        "        model.eval()\n",
        "        valid_preds, valid_labels = [], []\n",
        "\n",
        "        for batch in test_dataloader:   \n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=None)\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.squeeze(1).to('cpu').numpy()\n",
        "            batch_preds = np.argmax(logits, axis=1)\n",
        "            batch_labels = np.hstack(label_ids)\n",
        "\n",
        "            valid_preds.extend(batch_preds)\n",
        "            valid_labels.extend(batch_labels)\n",
        "\n",
        "        with open('log.txt', 'a') as f:\n",
        "            f.write(\"Accuracy: {0:.2f}%\".format(\n",
        "              accuracy_score(valid_labels, valid_preds) * 100\n",
        "            ))\n",
        "            f.write(\"Matthews: {0:.2f}%\".format(\n",
        "              matthews_corrcoef(valid_labels, valid_preds) * 100\n",
        "            ))\n",
        "        model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OayV0WJmM0Br"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v87esspjVCb"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYtgZWLjjXGk",
        "outputId": "e4073083-81b5-4238-b0a7-9299b66457ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = 'cuda'\n",
        "bert_config = BertConfig.from_json_file('./gdrive/My Drive/Transformer/bert_config.json')\n",
        "model = BertForSequenceClassification(bert_config, 5)\n",
        "model.to(device)\n",
        "model = torch.nn.DataParallel(model)\n",
        "model.load_state_dict(torch.load('./gdrive/My Drive/weights5000.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxws_7e3jh_1"
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(vocab_file='./gdrive/My Drive/Transformer/vocab.txt', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svG7T-R5jsb7"
      },
      "source": [
        "def predict(sentence, tokenizer, max_len):\n",
        "#     print(sentence)\n",
        "    tokens_a = tokenizer.tokenize(sentence)\n",
        "    if len(tokens_a) > max_len - 2:\n",
        "        tokens_a = tokens_a[0:(max_len - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "    while len(input_ids) < max_len:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "    input_ids = torch.LongTensor(input_ids).unsqueeze(0)\n",
        "    input_mask = torch.LongTensor(input_mask).unsqueeze(0)\n",
        "    a = time.time()\n",
        "\n",
        "    logits = model(input_ids.cuda(), None, input_mask.cuda())\n",
        "    logits = logits.squeeze(0)\n",
        "    \n",
        "    b = time.time()\n",
        "    logits = F.softmax(logits, dim=-1)\n",
        "    clas = logits.argmax().item()\n",
        "    return clas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSxzKBPAjuEH",
        "outputId": "877505cf-a3e6-49c6-c2db-806195db7a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "maps[predict(\"Василий Ломаченко боксировал с Теофимо Лопесом с травмой плеча\", tokenizer, 512)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sport'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBeGRKDRjyh8",
        "outputId": "5858acd7-76aa-4f12-84d7-8bf4d8ae5d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "maps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sport', 'society', 'auto', 'business', 'economic'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6a0Sryrj1Wb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}